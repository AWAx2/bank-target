# ＜顧客ターゲティングコンペ＞
19/558 位<br>
以下はただの日記みたいな感想みたいなやつ
## ☆コンペの課題
顧客属性データおよび、過去のキャンペーンでの接触情報に基づいて口座を開設したかを予測するモデルの構築。評価関数はAUC。
## ☆データセット
　欠損値なしのデータセットだった（unknownはあり）。Tier限定コンペだったので、そこを考えて欠損値のあるデータを消去してくれたのかも。
コンペ終了後のフォーラムにも書かれていたけど、オリジナルデータと比べて魔改造されている部分もあった。
## ☆感想
　上にも書いたとおり、データセットがオリジナルのものと比べて魔改造されている部分があった。balanceとか範囲ごとにグールプ化してみたり、
新しい特徴量をいくつか作ったけど、スコア改善にはあまり貢献しなかった。
もしかしたら、オリジナルから今回のコンペ用のデータセットを作るときに行った処理になにかあるのかも。
訓練データもテストデータも分布が似ていて、びっくりするほど綺麗なデータセットだったので何を目指して今回のデータセットを作ったのか気になる。
というわけで、コンペの前半でフィーチャーエンジニアリングとおさらば。ちなみに、今回のコンペでは魔改造を受けていたbalanceとpdaysは特徴量から消した方が良かったらしい。
自分は作ったモデルの中にbalanceやpdaysの重要度が高いモデルがあったので捨てる選択肢は浮かばなかったけど、やっぱりオリジナルデータが大事。本当に大事。いい勉強になった！<br>
　一方のモデルは、RF、XGB、LGB、CBを初めに採用。アンサンブルする予定だったので、パラメータはちょっと過学習気味になるようにoptunaで調整。
スコアが伸び悩んできたところでNNを追加。NNは精度的には0.83くらいだったけど、追加したらスコアが上がったのでモデルの多様性を増やすことは大事だと再認識。
ただ、最終的には公式のベンチマークを超えていたXGB、LGB、CBの3つのモデルからLGBをgbdtとdartに分けた4モデルを採用。Stackingでメタモデルを作ったけど、
logregのモデルだけだったせいかスコア改善には繋がらなかった。なので、メタモデルを加えた5モデルの予測値の加重平均で最終的な予測値を出した。
これは今回のコンペみたいなLBそのものが結果のコンペでしか通用しない技だと思う。<br>
　今回のコンペは0.86超えが一つの壁だったみたいで、それを超すことができなかったのはかなり悔しい。使い方を知らなかったからスルーしてしまったけど、
フォーラムにあったDeepTablesを使えば0.86いけたかもみたいなところもあって余計悔しい。
でも、大学での研究も終わって久しぶりにこういったコンペサイトでテーブルコンペをできたのは色々思い出すことが出来てよかったし、
「kaggleやろう」って熱も出てきたのでプラスになることが多いコンペだった。
ただ、正直言って10月からニートになるかもしれないこの状況の中でよくコンペに参加したなって思う。クレイジー。